---
title: read papers
published_date: "2021-05-24 20:23:50 +0000"
layout: default.liquid
is_draft: false
--- 
# read papers

## paper1:DEGREE-QUANT: QUANTIZATION-AWARE TRAINING FOR GRAPH NEURAL NET WORKS

### motivation

## paper2: GEBT: Drawing Early-Bird Tickets in Graph Convolutional Network Training

### words
* notoriously 臭名昭著的
* dubbed
* exacerbated
* intertwined
* paramount 最重要的

